HW 2 for P8105 - hlz2108
================

The code chunk below loads libraries.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

\#\#Problem 1

Reading in Mr. Trash Wheel dataset.

``` r
trash_wheel_df =
  read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols ("A:N")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) %>% 
view
```

Read precipitation data\!

``` r
precip_2018 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
  
precip_2017 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This data set contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

\#\#Problem 2

Reading in and cleaning NYC Transit Data.

``` r
NYC_transit_df = 
  read_csv(
    "./data/NYC_Transit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry,`YES` = TRUE, `NO` = FALSE )) %>% 
view
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This data set contains information related to each entrance and exit for
each subway station in NYC. In our final dataset, I have only included
the following variables: line, station\_name, station\_latitude,
station\_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entry, vending,
entrance\_type, ada and removed several others, such as entrance and
exit locations. In cleaning the data, the entry variable was converted
into a logical variable. There are a total of 1868 rows and 19 columns
in our final dataset.

The data is not tidy in the final dataset as there are many NA variables
in the route columns. Also, route number is spread across 11 separate
columns instead of being condensed into 1.

There are a total of 465 distinct stations.

468 stations are ADA compliant.

The proportion of station entrances/exits without vending that allow
entrance are 0.3770492.

``` r
transit_df = 
  NYC_transit_df %>% 
  mutate_at(vars(route1:route11), replace_na, 'None') %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% 
  view()

transit_df
```

    ## # A tibble: 20,548 x 10
    ##    line  station_name station_latitude station_longitu… entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  2 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  3 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  4 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  5 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  6 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  7 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  8 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  9 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ## 10 4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ## # … with 20,538 more rows, and 4 more variables: entrance_type <chr>,
    ## #   ada <lgl>, route_number <chr>, route_name <chr>

``` r
ATrain_df = 
  filter(transit_df, route_name == "A")
```

There are 60 distinct stations that serve the A train.

Of the stations that serve the A train, 107 stations are ADA compliant.

\#\#Problem 3

Reading in FiveThirtyEight Data.

``` r
pols_month_df = read_csv("./data/fivethirtyeight_datasets/pols-month.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
unemployment_df = read_csv("./data/fivethirtyeight_datasets/unemployment.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )
