HW 2 for P8105 - hlz2108
================
Helen Zhang
September 30, 2020

The code chunk below loads libraries.

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Reading in Mr. Trash Wheel dataset.

``` r
trash_wheel_df =
  read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols ("A:N")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) %>% 
view
```

Read precipitation data\!

``` r
precip_2018 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
  
precip_2017 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation. In the following code chunk, I create
a “helper” tibble that contains pairs of numeric and character ways of
representing month, and then merge that (using month number as a key)
with the precipitation dataset. This technique is one I use often when I
need to recode a moderate or large number of values for a variable.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This data set contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

Reading in and cleaning NYC Transit Data.

``` r
NYC_transit_df = 
  read_csv(
    "./data/NYC_Transit_Data.csv", col_types = cols(
      Route8 = col_character(),
      Route9 = col_character(),
      Route10 = col_character(),
      Route11 = col_character()
    )) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry,`YES` = TRUE, `NO` = FALSE )) %>% 
view
```

This data set contains information related to each entrance and exit for
each subway station in NYC. In this first code chunk, I have kept only
information on the station name, the line it is on, latitude and
longitudinal coordinates, routes they serve, if entry is allowed and
what type of entry it is, and whether the station is ADA compliant. To
clean this dataset, I first reformatted the names using the janitor
package. I then recoded the entry variable as a logical vector, so that
entry was coded as either True or False instead of Yes or No. After
cleaning the data, the dimensions of the data set are 1868 rows by 19
columns. This dataset is not tidy at the moment as there are still a
number of NA values and routes are spread across 11 columns and not
condensed into 1.

There are a total of 465 distinct stations.

84 stations are ADA compliant.

The proportion of station entrances/exits without vending that allow
entrance are 0.3770492.

The code chunk below creates a dataset that tidies up the previous NYC
Transit dataset, and reformats the data so that the route number and
route name are distinct variables.

``` r
transit_tidy_df =
  NYC_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_line") %>% 
  relocate("route_line") %>% 
  drop_na(route_line) %>% 
  select(-route_number) %>% 
  view()

transit_tidy_df
```

    ## # A tibble: 4,270 x 9
    ##    route_line line  station_name station_latitude station_longitu… entry vending
    ##    <chr>      <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 R          4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  2 R          4 Av… 25th St                  40.7            -74.0 TRUE  YES    
    ##  3 N          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  4 R          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  5 N          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  6 R          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  7 N          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  8 R          4 Av… 36th St                  40.7            -74.0 TRUE  YES    
    ##  9 R          4 Av… 45th St                  40.6            -74.0 TRUE  YES    
    ## 10 R          4 Av… 45th St                  40.6            -74.0 TRUE  YES    
    ## # … with 4,260 more rows, and 2 more variables: entrance_type <chr>, ada <lgl>

In our final dataset, there are a total of 4270 rows and 9 columns. The
data is tidy in the final dataset as route line has been condensed into
1 variable and the NA responses are no longer present.

The code chunk below creates a dataset that contains only stations that
serve the A Train.

``` r
ATrain_df = 
  filter(transit_tidy_df, route_line == "A")
```

There are 60 distinct stations that serve the A train.

Of the stations that serve the A train, 17stations are ADA compliant.

## Problem 3

**Reading in FiveThirtyEight data**

Cleaning and tidying up pols\_month dataset.

``` r
pols_month_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% view
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
        month_name = month.abb
    )

pols_tidy_df = 
    left_join(pols_month_df, month_df, by = "month") %>% 
  relocate(month_name, prez_gop, prez_dem) %>% 
  mutate(prez_gop = na_if(prez_gop, 0), prez_dem = na_if(prez_dem,0)) %>%
    pivot_longer(
    prez_gop:prez_dem,
    names_to = "president",
    values_to = "president_value") %>% 
  mutate(president = recode(president, `prez_gop` = 'gop', `prez_dem` = 'dem')) %>% 
  drop_na(president_value) %>% 
  arrange(year, month) %>% 
  select(-president_value, -month, -day) %>%
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  view()
```

Cleaning and tidying the snp.csv dataset.

``` r
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>%
  view
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"),
        month_name = month.abb
    )

snp_tidy_df = 
    left_join(snp_df, month_df, by = "month") %>%
  arrange(year, month) %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>%  
  relocate(year, month) %>% 
  view
```

Cleaning up and tidying unemployment dataset.

``` r
unemployment_tidy_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv", col_types = cols(
    Year = col_character()
    )) %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  rename(year = Year) %>% 
    view
```

Merging datasets together\!

``` r
snp_pols_df = 
  left_join(pols_tidy_df, snp_tidy_df, by = c("year" = "year", "month" = "month")) %>% view

FiveThirtyEight_df = 
  left_join(snp_pols_df, unemployment_tidy_df, by = c("year" = "year", "month" = "month")) %>% view
```

The pols-month dataset contains information on the political landscape
of the US, such as the number of national politicians who are democratic
or republican at the presidential, governor, and senate level at a
particular date. In cleaning this dataset, I cleaned the names using the
*janitor* package, and separated the date into three variables, year,
month and day, keeping only year and month for dataset consistency. I
then converted the month variable into their abbreviated month names.
Lastly, I created a new *president* variable that would reveal whether
the president at a particular month and year was either a republican of
democrat. I did this by combining the prez\_gop and prez\_dem variables
into 1 variable. Lastly, I arranged the data by month and year as the
leading columns so that I could merge it with my other datasets later
on.

The snp dataset contains information on the closing vales of the S\&P
stock index on the associated month and year. The data wrangling process
was similar to that in the pols-month dataset. After cleaning the
variable names, I began with breaking the date variable into three
separate ones: year, month and day, keeping only year and month. Month
was then converted into its abbreviated month name and the data was
arranged by year and month as the leading columns.

The unemployment data set contains information on the unemployment
percentage of a particular month in a year. For consistency, I
transformed the months columns (Jan-Dec) into rows using
*pivot\_longer*, so that I would have a month and unemployment variable.
I then arranged the dataset by year and month as the leading columns.

The final dataset, FiveThirtyEight\_df, merges the previous 3 datasets
together, by year and by month, creating a large dataset that contains
information on the political landscape, stock performance, and
unemployment percentages for a particular month and year. This final
dataset dimensions are 822 rows by 11 columns. The dataset contains
information between the years 1947 and 2015. One key variable in the
FiveThirtyEight dataset is that it shows you whether the president at a
certain month was either republican or democratic, as well as the
unemployment percentage and closing value for the S\&P stock index in
that month, indicators of economic performance. This information could
be useful for evaluating a president’s performance.
